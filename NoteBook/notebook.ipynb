{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import sentence_transformers\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the cwd\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# back to the main dire\n",
    "os.chdir(\"..\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract the data from the pdf files\n",
    "def extracted_data(data_dir):\n",
    "     loader = DirectoryLoader(path=data_dir,\n",
    "                              glob=\"*.pdf\",\n",
    "                              loader_cls=PyPDFLoader)\n",
    "     document = loader.load()\n",
    "     return document\n",
    "\n",
    "extracted_data = extracted_data(\"DataSet/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracted_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to split the data into chunks\n",
    "def chunking(extracted_data):\n",
    "     splitter = RecursiveCharacterTextSplitter(\n",
    "                                   chunk_size=1000,\n",
    "                                   chunk_overlap=200,\n",
    "                                   separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
    "                                   is_separator_regex=False\n",
    "                                   )\n",
    "     text_chunks = splitter.split_documents(extracted_data)\n",
    "     return text_chunks\n",
    "\n",
    "text_chunks = chunking(extracted_data=extracted_data)\n",
    "print(f\"Text Chunks: {len(text_chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to download the embedding model\n",
    "def download_embedding_model():\n",
    "     embedding_model = HuggingFaceEmbeddings(model_name=\"ibm-granite/granite-embedding-125m-english\")\n",
    "     return embedding_model\n",
    "\n",
    "embedding_model = download_embedding_model() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for embedding model\n",
    "embed = embedding_model.embed_query(\"Hello Word\")\n",
    "print(f\"Dimension: {len(embed)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Pinecone vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index_name = \"question-answer-chatbot\"\n",
    "pc.create_index(name=index_name,\n",
    "                dimension=768,\n",
    "                metric=\"cosine\",\n",
    "                spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_pinecone_vector_store(documents, index_name, embedding, retries=3, delay=5):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            docsearch = PineconeVectorStore.from_documents([], index_name=index_name, embedding=embedding)\n",
    "            print(\"✅ Pinecone Vector Store created.\")\n",
    "\n",
    "            for i in tqdm(range(0, len(documents)), desc=\"Uploading documents\", unit=\"doc\"):\n",
    "                docsearch.add_documents([documents[i]])\n",
    "\n",
    "            print(\"✅ All documents uploaded successfully.\")\n",
    "            return docsearch\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ Attempt {attempt + 1} failed: {e}\")\n",
    "            if attempt < retries - 1:\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                raise e\n",
    "\n",
    "\n",
    "docsearch = initialize_pinecone_vector_store(\n",
    "    documents=text_chunks,\n",
    "    index_name=index_name,\n",
    "    embedding=embedding_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medibot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
